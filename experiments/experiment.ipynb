{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the code to connect to ollama and ask a question\n",
    "\n",
    "import asyncio\n",
    "from ollama import AsyncClient\n",
    "import argparse\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.markdown import Markdown\n",
    "from rich.live import Live\n",
    "from rich.text import Text\n",
    "from rich.style import Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "# Initialize the Ollama client\n",
    "client = AsyncClient(host='http://localhost:11434')\n",
    "async def chat_with_ollama(model: str, prompt: str):\n",
    "    try:\n",
    "        full_response = \"\"\n",
    "        async for response in await client.chat(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            stream=True\n",
    "        ):\n",
    "            # Extract the new content from the response\n",
    "            if 'message' in response:\n",
    "                new_content = response['message'].get('content', '')\n",
    "                full_response += new_content\n",
    "                \n",
    "                # Clear and display the accumulated response\n",
    "                clear_output(wait=True)\n",
    "                print(full_response, end='', flush=True)\n",
    "        \n",
    "        print(\"\\n\\nResponse completed\")\n",
    "        return full_response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(model='deepseek-r1:70b', created_at='2025-01-30T03:22:43.435191Z', done=True, done_reason='stop', total_duration=69307835875, load_duration=9106004042, prompt_eval_count=10, prompt_eval_duration=15899000000, eval_count=314, eval_duration=44299000000, message=Message(role='assistant', content='', images=None, tool_calls=None))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Response completed'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chat_with_ollama(\"deepseek-r1:70b\", \"What is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chaoseng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
